
from __future__ import absolute_import, unicode_literals
import os
import django
import uuid

from unittest import skip
from typing import List

from django.conf import settings
from django.test import TestCase

from nexus.users.models import User
from nexus.orgs.models import Org
from nexus.actions.models import Flow
from nexus.intelligences.models import (
    IntegratedIntelligence, ContentBase, ContentBaseAgent, ContentBaseInstruction, ContentBaseLink
)
from nexus.usecases.intelligences.get_by_uuid import get_llm_by_project_uuid
from nexus.usecases.intelligences.intelligences_dto import LLMDTO
from nexus.usecases.intelligences.create import create_llm
from nexus.usecases.intelligences.retrieve import get_file_info
from nexus.usecases.logs.create import CreateLogUsecase

from nexus.intelligences.llms.chatgpt import ChatGPTClient
from nexus.intelligences.llms.wenigpt import WeniGPTClient
from nexus.logs.models import MessageLog, Message as MessageModel


from router.classifiers import Classifier
from router.route import route
from router.tasks.tasks import start_route
from router.entities import (
    Message,
    LLMSetupDTO,
    InstructionDTO
)
from router.tests.mocks import (
    TestException,
    MockBroadcastHTTPClient,
    MockFlowStartHTTPClient,
    MockIndexer,
    MockLLMClient,
    ContentBaseTestRepository,
    FlowsTestRepository,
    MessageLogsTestRepository
)

from router.clients.preview.simulator.broadcast import SimulateBroadcast
from router.clients.preview.simulator.flow_start import SimulateFlowStart

os.environ.setdefault("DJANGO_SETTINGS_MODULE", "nexus.settings")

django.setup()


class RouteTestCase(TestCase):
    def setUp(self) -> None:
        self.user = User.objects.create(email='test@user.com')

        project_name = "Test Project"

        self.org = Org.objects.create(created_by=self.user, name='Test Org')
        self.org.authorizations.create(role=3, user=self.user)
        self.project = self.org.projects.create(
            uuid="7886d8d1-7bdc-4e85-a7fc-220e2256c11b",
            name=project_name,
            created_by=self.user
        )
        self.intelligence = self.org.intelligences.create(
            name=project_name, created_by=self.user)
        self.content_base = ContentBase.objects.create(
            title=project_name,
            intelligence=self.intelligence,
            created_by=self.user,
            is_router=True
        )
        self.integrated_intel = IntegratedIntelligence.objects.create(
            project=self.project,
            intelligence=self.intelligence,
            created_by=self.user,
        )

        self.agent = ContentBaseAgent.objects.create(
            name="Doris",
            role="Vendas",
            personality="Criativa",
            goal="Vender os produtos",
            content_base=self.content_base
        )
        self.flow = Flow.objects.create(
            content_base=self.content_base,
            uuid=uuid.uuid4(),
            flow_uuid=uuid.uuid4(),
            name="Compras",
            prompt="Fluxo de compras de roupas"
        )
        self.fallback = Flow.objects.create(
            content_base=self.content_base,
            uuid=uuid.uuid4(),
            flow_uuid=uuid.uuid4(),
            name="Fluxo de fallback",
            prompt="Fluxo de fallback",
            fallback=True,
        )
        self.instruction = ContentBaseInstruction.objects.create(
            content_base=self.content_base,
            instruction="Teste Instruction"
        )

        llm_dto = LLMDTO(
            user_email=self.user.email,
            project_uuid=str(self.project.uuid),
            setup={
                'temperature': settings.WENIGPT_TEMPERATURE,
                'top_p': settings.WENIGPT_TOP_P,
                'top_k': settings.WENIGPT_TOP_K,
                'max_length': settings.WENIGPT_MAX_LENGHT,
            }
        )
        self.llm = create_llm(llm_dto=llm_dto)
        self.link = ContentBaseLink.objects.create(
            content_base=self.content_base,
            link="http://test.co",
            created_by=self.user,
        )

    def test_chatgpt_prompt(self):
        from router.repositories.orm import ContentBaseORMRepository

        content_base = self.content_base

        content_base_repository = ContentBaseORMRepository()
        instructions: List[InstructionDTO] = content_base_repository.list_instructions(
            content_base.uuid
        )
        instructions: List[str] = [
            instruction.instruction for instruction in instructions
        ]
        agent = self.agent

        chunks = ["Lorem Ipsum", "Dolor Sit Amet"]

        prompt = ChatGPTClient().format_prompt(instructions, chunks, agent.__dict__)
        assert "{{" not in prompt

    def test_wenigpt_prompt(self):
        from router.repositories.orm import ContentBaseORMRepository

        content_base = self.content_base

        content_base_repository = ContentBaseORMRepository()
        instructions: List[InstructionDTO] = content_base_repository.list_instructions(
            content_base.uuid
        )
        instructions: List[str] = [
            instruction.instruction for instruction in instructions
        ]
        agent = self.agent

        chunks = ["Lorem Ipsum", "Dolor Sit Amet"]
        question = "Ipsum Lorem"

        prompt = WeniGPTClient(model_version=settings.WENIGPT_DEFAULT_VERSION).format_prompt(
            instructions, chunks, agent.__dict__, question)
        assert "{{" not in prompt

    def test_wenigpt_no_context_prompt(self):
        from router.repositories.orm import ContentBaseORMRepository

        content_base = self.content_base

        content_base_repository = ContentBaseORMRepository()
        instructions: List[InstructionDTO] = content_base_repository.list_instructions(
            content_base.uuid
        )
        instructions: List[str] = [
            instruction.instruction for instruction in instructions
        ]
        agent = self.agent

        chunks = []
        question = "Ipsum Lorem"

        prompt = WeniGPTClient(model_version=settings.WENIGPT_DEFAULT_VERSION).format_prompt(
            instructions, chunks, agent.__dict__, question)
        assert "{{" not in prompt

    def test_chatgpt_no_context_prompt(self):
        from router.repositories.orm import ContentBaseORMRepository

        content_base = self.content_base

        content_base_repository = ContentBaseORMRepository()
        instructions: List[InstructionDTO] = content_base_repository.list_instructions(
            content_base.uuid
        )
        agent = self.agent

        chunks = []

        prompt = ChatGPTClient().format_prompt(
            instructions,
            chunks,
            agent.__dict__
        )
        assert "{{" not in prompt

    def mock_messages(
        self,
        classification: str,
        fallback_flow=None,
        direct_message=MockBroadcastHTTPClient(),
        flow_start=MockFlowStartHTTPClient(),
    ):
        content_base = self.content_base
        agent = self.agent
        flow = self.flow

        project_uuid = str(self.project.uuid)

        message = Message(
            project_uuid=project_uuid,
            text="Lorem Ipsum",
            contact_urn="telegram:123455667"
        )

        log_usecase = CreateLogUsecase()
        log_usecase.create_message_log(
            text=message.text,
            contact_urn=message.contact_urn,
            source="router",
        )

        content_base_repository = ContentBaseTestRepository(
            content_base, agent)
        flows_repository = FlowsTestRepository(flow, fallback_flow)
        message_logs_repository = MessageLogsTestRepository(
            str(self.content_base.uuid)
        )

        llm_type = "chatgpt"
        llm_client = MockLLMClient.get_by_type(llm_type)

        llm_model = get_llm_by_project_uuid(project_uuid)
        llm_config = LLMSetupDTO(
            model=llm_model.model.lower(),
            model_version=llm_model.setup.get("version"),
            temperature=llm_model.setup.get("temperature"),
            top_k=llm_model.setup.get("top_k"),
            top_p=llm_model.setup.get("top_p"),
            token=llm_model.setup.get("token"),
            max_length=llm_model.setup.get("max_length"),
            max_tokens=llm_model.setup.get("max_tokens"),
        )

        if llm_config.model.lower() != "wenigpt":
            llm_client.token = llm_config.setup.get("token")

        flow_user_email = "email@test.com"

        return route(
            classification=classification,
            message=message,
            content_base_repository=content_base_repository,
            flows_repository=flows_repository,
            message_logs_repository=message_logs_repository,
            indexer=MockIndexer(file_uuid=str(self.link.uuid)),
            llm_client=llm_client(),
            direct_message=direct_message,
            flow_start=flow_start,
            llm_config=llm_config,
            flows_user_email=flow_user_email,
            log_usecase=log_usecase
        )

    def test_route_other(self):
        try:
            self.mock_messages(
                Classifier.CLASSIFICATION_OTHER,
                fallback_flow=self.fallback
            )
        except Exception as e:
            self.fail(f" test_route_other raised {e}!")

    def test_route_other_no_fallback(self):
        try:
            self.fallback.delete()
            self.mock_messages(Classifier.CLASSIFICATION_OTHER)
        except Exception as e:
            self.fail(f" test_route_other raised {e}!")

    def test_route_classify(self):
        try:
            self.mock_messages(self.flow.name)
        except Exception as e:
            self.fail(f" test_route_other raised {e}!")

    def test_route_preview_other_with_fallback_flow(self):
        response = self.mock_messages(
            Classifier.CLASSIFICATION_OTHER,
            fallback_flow=self.fallback,
            direct_message=SimulateBroadcast(
                host=None, access_token=None, get_file_info=get_file_info
            ),
            flow_start=SimulateFlowStart(host=None, access_token=None)
        )
        self.assertEquals(response.get("type"), "flowstart")

    def test_route_preview_other_no_fallback_flow(self):
        response = self.mock_messages(
            Classifier.CLASSIFICATION_OTHER,
            direct_message=SimulateBroadcast(
                host=None, access_token=None, get_file_info=get_file_info
            ),
            flow_start=SimulateFlowStart(host=None, access_token=None)
        )
        self.assertEquals(response.get("type"), "broadcast")

    def test_route_preview_classify(self):
        response = self.mock_messages(
            self.flow.name,
            fallback_flow=self.fallback,
            direct_message=SimulateBroadcast(
                host=None, access_token=None, get_file_info=get_file_info
            ),
            flow_start=SimulateFlowStart(host=None, access_token=None)
        )
        self.assertEquals(response.get("type"), "flowstart")


@skip("Integration test, shouldn't run for coverage")
class StartRouteTestCase(TestCase):
    def setUp(self) -> None:
        project_uuid = "e8326ee9-ca88-49da-aaf3-8f35eb60e7dc"

        self.user = User.objects.create(email='test@user.com')

        self.org = Org.objects.create(created_by=self.user, name="org_name")
        self.auth = self.org.authorizations.create(user=self.user, role=3)
        self.project = self.org.projects.create(
            uuid=project_uuid, name="Projeto", created_by=self.user
        )
        self.intelligence = self.org.intelligences.create(
            created_by=self.user, name=self.project.name
        )
        self.integrated_intelligence = IntegratedIntelligence.objects.create(
            project=self.project,
            intelligence=self.intelligence,
            created_by=self.user
        )
        self.content_base = self.intelligence.contentbases.create(
            uuid="0aa8d243-0f99-4c75-8309-21a73d6bd223",
            created_by=self.user,
            title=self.project.name,
            is_router=True
        )
        self.agent = ContentBaseAgent.objects.create(
            name="Doris",
            role="Vendas",
            personality="Criativa",
            goal="Vender",
            content_base=self.content_base
        )
        self.flow = Flow.objects.create(
            flow_uuid="da2c0365-cabe-410b-bc15-4a42a237d91e",
            name="Teste router",
            prompt="Caso esteja interessado em testar o router",
            content_base=self.content_base
        )
        self.instruction = ContentBaseInstruction.objects.create(
            content_base=self.content_base, instruction="Responda sempre em esperanto"
        )

        llm_dto = LLMDTO(
            model="chatGPT",
            user_email=self.user.email,
            project_uuid=str(self.project.uuid),
            setup={
                'token': settings.OPENAI_API_KEY,
                'version': 'gpt-4-turbo',
                'temperature': settings.WENIGPT_TEMPERATURE,
                'top_p': settings.WENIGPT_TOP_P,
                'top_k': settings.WENIGPT_TOP_K,
                'max_length': settings.WENIGPT_MAX_LENGHT,
            }
        )
        self.llm = create_llm(llm_dto=llm_dto)

    def test_start_route(self):
        self.message = Message(
            project_uuid=str(self.project.uuid),
            text='quero comprar uma camisa',
            contact_urn='',
        )
        start_route(self.message.__dict__)

        msg = MessageModel.objects.first()
        self.assertEquals(msg.status, "S")


class LogUseCaseTestCase(TestCase):

    def setUp(self) -> None:
        project_uuid = "e8326ee9-ca88-49da-aaf3-8f35eb60e7dc"

        self.user = User.objects.create(email='test@user.com')

        self.org = Org.objects.create(created_by=self.user, name="org_name")
        self.auth = self.org.authorizations.create(user=self.user, role=3)
        self.project = self.org.projects.create(
            uuid=project_uuid, name="Projeto", created_by=self.user
        )

        self.message = Message(
            project_uuid=project_uuid,
            text='quero comprar uma camisa',
            contact_urn='telegram:123321#test',
        )
        self.log_usecase = CreateLogUsecase()
        self.log_usecase.create_message_log(
            source="router",
            text=self.message.text,
            contact_urn=self.message.contact_urn
        )

    def test_create(self):
        self.assertIsInstance(self.log_usecase.message, MessageModel)
        self.assertIsInstance(self.log_usecase.log, MessageLog)
        self.assertEquals(self.log_usecase.message.status, "P")

    def test_update_status_with_exception(self):
        try:
            raise TestException("Test Exception")
        except TestException as e:
            self.log_usecase.update_status("F", e)

        self.assertEquals(self.log_usecase.message.status, "F")

    def test_update_log_field(self):
        self.assertIsNone(self.log_usecase.log.chunks)

        chunks = ["Chunk 1", "Chunk 2", "Chunk 3"]

        self.log_usecase.update_log_field(
            chunks=chunks, project_id=self.project.uuid
        )
        self.assertEquals(self.log_usecase.log.chunks, chunks)
